{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "tweets = pd.read_csv('../data/train.csv', encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0  1   NaN     NaN       \n",
       "1  4   NaN     NaN       \n",
       "2  5   NaN     NaN       \n",
       "\n",
       "                                                                                                                                    text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all                                                                   \n",
       "1  Forest fire near La Ronge Sask. Canada                                                                                                  \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "\n",
       "   target  \n",
       "0  1       \n",
       "1  1       \n",
       "2  1       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets explore a few tweets\n",
    "print(len(tweets))\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550    I added a video to a @YouTube playlist http://t.co/wedWyn9kfS World Of Tanks - Battle Assistant Mod Bat Chat Arti kaboom                  \n",
       "551    YA BOY CLIP VS 4KUS FULL BATTLE\\n\\n@15MofeRadio @Heavybag201 @battle_dom @QOTRING @BattleRapChris @Hughes1128 \\n\\nhttps://t.co/7SPyDy1csc \n",
       "552    Indeed!! I am fully aware of that battle! I support you in that fight!!  https://t.co/MctJnZX4H8                                          \n",
       "553    It's baaaack!  Petersen's Bowhunting Battle of the Bows.  Make sure you head on over and cast your vote for your... http://t.co/FJ73gDvg2n\n",
       "554    #Tb #throwback ??\\n\\n??~ You want a battle? Here's a War! ~ ?? https://t.co/B0ZJWgmaIW                                                    \n",
       "555    Kelby Tomlinson mild-mannered 2nd baseman for a great metropolitan team fights a never-ending battle for hits RBI and the #SFGiants way.  \n",
       "556    Black Eye 9: A space battle occurred at Star M27329 involving 1 fleets totaling 1236 ships with 7 destroyed                               \n",
       "557    What really happened in the Taken King Story Trailer. A space battle that ripped a hole in Saturn. @EyTay @neur0sis http://t.co/ZYRZX6dfki\n",
       "558    THESE AFTER BATTLE ANIMATIONS ARE SO FUCKING MUCH                                                                                         \n",
       "559    See what happens with NO Battle of the Block @CBSBigBrother!?! ???? finally                                                               \n",
       "560    #DU19 who gon get in this rap battle with me                                                                                              \n",
       "561    Do Your Own Thing: The Battle of Internal vs External Motivation: http://t.co/w9P3hAuHEi                                                  \n",
       "562    Check out this item I just got! [Phantasmal Cummerbund] http://t.co/qrHJEI7gRq #Warcraft                                                  \n",
       "563    A young German stormtrooper engaged in the Battle of the Somme 1916. [800 ÌÑ 582 ] http://t.co/yxvMifLvc4                                 \n",
       "564    I liked a @YouTube video http://t.co/9Vw0uQQi1y Marvel VS DC (Avengers Battle!)                                                           \n",
       "565    @UtahCanary sigh daily battle.                                                                                                            \n",
       "566    @SexyDragonMagic I've come to the realization that I just don't have the attention span for mass battle games. Both painting and playing. \n",
       "567    @DetroitPls interested to see who will win this battle                                                                                    \n",
       "568    Battle of the GOATS  https://t.co/ofECs6tcvC                                                                                              \n",
       "569    STAR WARS POWER OF THE JEDI COLLECTION 1 BATTLE DROID HASBRO - Full read by eBay http://t.co/yI30ZgiZsW http://t.co/2jGVhw7YZs            \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for text information and make sure there are no weird characters\n",
    "tweets['text'].iloc[550:570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the text has multiple links in the body so we need to define a function to delete those hyperlinks\n",
    "import re\n",
    "def remove_urls(text):\n",
    "    # Remove urls taking into consideration http and https links\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    text = re.sub(r\"http?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = re.sub(r'\\b\\d+\\b', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accident center lane blocked in #SantaClara on US-101 NB before Great America Pkwy #BayArea #Traffic  '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(tweets['text'].iloc[69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rene Ablaze &amp; Jacinta - Secret 2k13 (Fallen Skies Edit) - Mar      https://t.co/7MLMsUzV1Z'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_numbers(tweets['text'].iloc[62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cleaned = tweets['text'].tolist()\n",
    "text_cleaned = [remove_urls(x) for x in text_cleaned]\n",
    "text_cleaned = [remove_numbers(x) for x in text_cleaned]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this excersice I will explore more classic models such as tf-idf with logistic regression, svm and neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We start with tf-idf\n",
    "\n",
    "We will use a Term Frequency- Inverse document frequency model as the baseline for this task. We will use the particularly the TfidfVectorizer from scikit-learn. The TfidfVectorizer expects a list of texts, so we need to transform the text column (the tweet column) into a list before feeding it to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfid_vectorizer = TfidfVectorizer(use_idf = True, \n",
    "                                  smooth_idf=True, sublinear_tf=True,\n",
    "                                  encoding = 'utf-8', lowercase = False, \n",
    "                                  stop_words = 'english',\n",
    "                                  token_pattern=r'\\w{1,}',\n",
    "                                  ngram_range = (1,3),\n",
    "                                 max_features = 10000)\n",
    "\n",
    "\n",
    "X_text = tfid_vectorizer.fit_transform(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into test and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_text,\n",
    "                                                   tweets['target'].tolist(),\n",
    "                                                   stratify = tweets['target'].tolist(),\n",
    "                                                   test_size = 0.3, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test Set Results---\n",
      "Accuracy with logreg: 0.8047285464098074\n",
      "F1 with logreg: 0.7932575257569595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84      1303\n",
      "           1       0.85      0.66      0.74       981\n",
      "\n",
      "    accuracy                           0.80      2284\n",
      "   macro avg       0.82      0.79      0.79      2284\n",
      "weighted avg       0.81      0.80      0.80      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_valid)\n",
    "print(\"---Test Set Results---\")\n",
    "print(\"Accuracy with logreg: {}\".format(accuracy_score(y_valid, y_pred)))\n",
    "print(\"F1 with logreg: {}\".format(f1_score(y_valid, y_pred, average = 'macro')))\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training f1 score: 0.9458612120830379\n",
      "validation f1 score: 0.7292414449630739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.78      1303\n",
      "           1       0.73      0.63      0.67       981\n",
      "\n",
      "    accuracy                           0.74      2284\n",
      "   macro avg       0.74      0.73      0.73      2284\n",
      "weighted avg       0.74      0.74      0.74      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try the xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(max_depth=25, n_estimators=1000, learning_rate=0.10, nthread = 2, \n",
    "                              colsample_bytree=.7, gamma=0, reg_alpha=4, \n",
    "                              objective='binary:logistic', eta=0.3, silent=1, \n",
    "                              subsample=0.8).fit(X_train, y_train) \n",
    "\n",
    "xgb_prediction = xgb_model.predict(X_valid)\n",
    "\n",
    "\n",
    "print('training f1 score:', f1_score(y_train, xgb_model.predict(X_train), average='macro'))\n",
    "print('validation f1 score:', f1_score(y_valid, xgb_model.predict(X_valid), average='macro'))\n",
    "print(classification_report(y_valid, xgb_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "test_data = pd.read_csv('../data/test.csv', encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0  0   NaN     NaN       \n",
       "1  2   NaN     NaN       \n",
       "2  3   NaN     NaN       \n",
       "3  9   NaN     NaN       \n",
       "4  11  NaN     NaN       \n",
       "\n",
       "                                                                                               text  \n",
       "0  Just happened a terrible car crash                                                                \n",
       "1  Heard about #earthquake is different cities, stay safe everyone.                                  \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all  \n",
       "3  Apocalypse lighting. #Spokane #wildfires                                                          \n",
       "4  Typhoon Soudelor kills 28 in China and Taiwan                                                     "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3263"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for submission\n",
    "text_cleaned_submission = test_data['text'].tolist()\n",
    "text_cleaned_submission = [remove_urls(x) for x in text_cleaned_submission]\n",
    "text_cleaned_submission = [remove_numbers(x) for x in text_cleaned_submission]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform new clean data to \n",
    "X_text_submission = tfid_vectorizer.fit_transform(text_cleaned_submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_prediction_submmision = xgb_model.predict(X_text_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_prediction_submmision.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new dataframe with predictions\n",
    "test_data['target'] = xgb_prediction_submmision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0  0   NaN     NaN       \n",
       "1  2   NaN     NaN       \n",
       "\n",
       "                                                               text  target  \n",
       "0  Just happened a terrible car crash                                0       \n",
       "1  Heard about #earthquake is different cities, stay safe everyone.  0       "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "test_data[['id','target']].to_csv(\"../data/submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub,X_valid_sub,y_train,y_valid = train_test_split(X_text,\n",
    "                                                   tweets['target'].tolist(),\n",
    "                                                   stratify = tweets['target'].tolist(),\n",
    "                                                   test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the text data and tokenize it. We need to make sure spacy gpu is working to \n",
    "# speed up calculations.\n",
    "spacy.require_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# check the default components\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time tweets_posted=list(nlp.pipe(tweets['text'].tolist(), batch_size=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(tweets['text'].tolist())\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_posted[0:11]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
